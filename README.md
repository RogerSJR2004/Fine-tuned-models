# ğŸ§  Rogerâ€™s Fine-Tuned LLMs Collection

## ğŸ“Œ About This Repository

This repo is a showcase of all the **language models Iâ€™ve fine-tuned** using **Hugging Face + Unsloth + LoRA**.
My focus is on building **lightweight, efficient, and instruction-following models** that can solve real-world problems in:

*  **Multi-language tasks** (Tamil + English)
*  **Summarization & Q\&A**
*  **Math & reasoning**
*  **Custom domain tasks** (finance, education, spiritual apps, etc.)

Each model here is uploaded to Hugging Face with an interactive demo, so you can try them directly.

---

## âœ… Whatâ€™s Inside

* **TinyLlama Instruction Fine-Tuned v1** â†’ (Q\&A, translation, summarization, reasoning)
* **Coming Soon**:

  * Tamil-English conversational model
  * Finance-focused instruction model
  * Bible AI assistant (Tamil + English)

---

## ğŸš€ Vision

I believe **small & efficient models** can have a massive impact when adapted to the **right domain**.
Instead of training billion-parameter models, my goal is to:

* Build **custom, domain-specific LLMs** for **education, finance, rural apps, and spiritual tools**.
* Share open-source models so others can **learn, experiment, and contribute**.
* Create **lightweight demos** that can run on limited hardware (GPUs/CPUs).

---

## ğŸ“Š Tech Stack

* **Base Models**: TinyLlama, Mistral, Llama-3 (planned)
* **Frameworks**: Unsloth, Hugging Face Transformers, PEFT, LoRA
* **Training**: Google Colab / Local GPU setups
* **Deployment**: Hugging Face Spaces (demo hosting)

---

## ğŸ¤ Contribution

* Got ideas? Want to collaborate? Feel free to open an **issue** or submit a **PR**.
* If youâ€™re also into fine-tuning, letâ€™s connect â€” Iâ€™d love to explore joint projects.

---

## ğŸ‘¨â€ğŸ’» Author

Created by **Roger_SJR**

* ğŸŒ [Hugging Face Profile](https://huggingface.co/rogersam)
* ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/rogersamuel17/)

---

âš¡ *This repo is a work in progress. Each update will include new fine-tuned models, training details, and demos. Stay tuned!*

