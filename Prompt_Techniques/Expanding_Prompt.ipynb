{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkwcofTS99a6",
        "outputId": "15ed6d90-98bf-422f-c0a5-38ceac56f7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbs740T5-uAO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=\"--\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JDnl59qZ-y7T"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"openai/gpt-oss-20b\"):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJ_7wk5-73p"
      },
      "source": [
        "# Customize the automated reply to a customer email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CmND739_-05N"
      },
      "outputs": [],
      "source": [
        "# given the sentiment from \"inferring\",\n",
        "# and the original customer message, customize the email\n",
        "sentiment = \"negative\"\n",
        "\n",
        "# customer message about GraceUp technical issue\n",
        "review = f\"\"\"\n",
        "I’ve been using GraceUp for a few months now, and while I really\n",
        "like the features, I’ve been running into some frustrating issues.\n",
        "Over the last week, the dashboard has been loading very slowly,\n",
        "sometimes taking over a minute just to show basic analytics.\n",
        "On top of that, the model inference requests are timing out more\n",
        "frequently, especially during peak hours. I tried clearing cache\n",
        "and switching networks, but the issue still persists.\n",
        "\n",
        "What makes it more disappointing is that I reached out to customer\n",
        "support, but the only reply I got was a generic “we’re working on it”\n",
        "message. No timeline, no transparency. For a platform that markets\n",
        "itself as reliable for production AI, this is a huge letdown.\n",
        "\n",
        "I really want to keep using GraceUp because the tools are powerful\n",
        "when they work, but unless performance improves and support becomes\n",
        "more responsive, I’ll have to start exploring alternatives.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7hgbEtO-_Pc",
        "outputId": "274d1d37-859b-4577-ec2e-c6ffbce2e18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject: We’re on it – Improving Your GraceUp Experience\n",
            "\n",
            "Dear [Customer Name],\n",
            "\n",
            "Thank you for taking the time to share your experience. I’m sorry to hear about the slow dashboard loading, frequent inference timeouts, and the lack of detailed support you received. I understand how frustrating this can be, especially when you rely on GraceUp for production AI.\n",
            "\n",
            "Our engineering team is actively investigating the performance issues you described, and we’re working to provide a clear timeline for resolution. In the meantime, please feel free to reach out directly to our dedicated support channel at support@graceup.com or call us at 1‑800‑GRACEUP. A senior engineer will personally follow up with you and keep you updated.\n",
            "\n",
            "We value your business and are committed to restoring the reliability you expect from GraceUp. Thank you for your patience and for giving us the opportunity to improve.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yUM83bL_xCJ",
        "outputId": "ed1f3f11-c56b-473b-b765-3e87f670dc03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject: We’re on it – Improving Your GraceUp Experience\n",
            "\n",
            "Dear [Customer Name],\n",
            "\n",
            "Thank you for taking the time to share your experience with GraceUp. I’m sorry to hear about the slow dashboard loading, frequent inference timeouts, and the lack of detailed support you received. Your feedback is invaluable, and we’re actively working on performance enhancements and clearer communication.\n",
            "\n",
            "Please feel free to reach out directly to our dedicated support team at support@graceup.com or call us at 1‑800‑GRACEUP. We’ll provide a concrete timeline for the fixes and keep you updated on progress.\n",
            "\n",
            "We appreciate your patience and your continued interest in GraceUp. Your satisfaction is our priority, and we’re committed to delivering the reliable, production‑grade experience you expect.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ],
      "source": [
        "# Remind the model to use details from the customer's email\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzUy46kO_7yY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
