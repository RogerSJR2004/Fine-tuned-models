{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPX1XZ0VqXA6",
        "outputId": "af63644f-5743-4063-a0a9-0e8a7fd1ce1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/131.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ],
      "source": [
        "# Transforming\n",
        "\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZeRewvXvakr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=\"--\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SYO-fQLJveOt"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"openai/gpt-oss-20b\"):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdrETSulyKtb",
        "outputId": "6054e34c-1c8a-495e-ffca-1ec158c864a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-851501473.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  response = get_completion(prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hola, me gustaría pedir una licuadora.\n"
          ]
        }
      ],
      "source": [
        "#Translation\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order a blender```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hGH6biW6Y5U",
        "outputId": "030c91ce-f22e-43b3-add5-b74795f1e783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "That sentence is in **French**.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkydUK9f6dPW",
        "outputId": "8dba05aa-83df-4318-9a70-db24f6968b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Original:**  \n",
            "I want to order a basketball  \n",
            "\n",
            "**French:**  \n",
            "Je souhaite commander un ballon de basket.  \n",
            "\n",
            "**Spanish:**  \n",
            "Quiero pedir un balón de baloncesto.  \n",
            "\n",
            "**English (pirate‑style):**  \n",
            "I be wantin’ to order a basketball, arrr!\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```I want to order a basketball```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_beFyt56fkX",
        "outputId": "4d472838-dcd1-4c9c-8ee6-b8db52d39f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Formal (usted):**  \n",
            "¿Le gustaría pedir una almohada?\n",
            "\n",
            "**Informal (tú):**  \n",
            "¿Te gustaría pedir una almohada?\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to Spanish in both the \\\n",
        "formal and informal forms:\n",
        "'Would you like to order a pillow?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_JcnSyIC6mDl"
      },
      "outputs": [],
      "source": [
        "# Universal Translator (AI & LLM related)\n",
        "\n",
        "user_messages = [\n",
        "  \"Mi modelo de lenguaje tarda demasiado en generar respuestas.\",   # My language model takes too long to generate responses\n",
        "  \"我的聊天机器人没有理解上下文。\",                                   # My chatbot did not understand the context\n",
        "  \"Mon IA génère parfois des réponses incohérentes.\",               # My AI sometimes generates incoherent answers\n",
        "  \"Il modello non riconosce correttamente le entità nominate.\",     # The model does not correctly recognize named entities\n",
        "  \"Mój system AI zużywa zbyt dużo pamięci RAM.\"                     # My AI system uses too much RAM\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miIs_jl96q7c",
        "outputId": "20072681-58af-4bda-da18-4687ecf7478c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original message (That sentence is in **Spanish**.): Mi modelo de lenguaje tarda demasiado en generar respuestas.\n",
            "**English:**  \n",
            "My language model takes too long to generate responses.\n",
            "\n",
            "**Korean:**  \n",
            "내 언어 모델이 응답을 생성하는 데 너무 오래 걸립니다. \n",
            "\n",
            "Original message (That sentence is in **Chinese (Simplified)**. It reads:\n",
            "\n",
            "> 我的聊天机器人没有理解上下文。  \n",
            ">  \n",
            "> *Translation:* “My chatbot did not understand the context.”): 我的聊天机器人没有理解上下文。\n",
            "**English:**  \n",
            "My chatbot did not understand the context.\n",
            "\n",
            "**Korean:**  \n",
            "내 챗봇이 문맥을 이해하지 못했습니다. \n",
            "\n",
            "Original message (That sentence is in **French**.): Mon IA génère parfois des réponses incohérentes.\n",
            "**English:**  \n",
            "\"My AI sometimes generates incoherent responses.\"\n",
            "\n",
            "**Korean:**  \n",
            "\"내 AI는 가끔 일관성 없는 답변을 생성합니다.\" \n",
            "\n",
            "Original message (That sentence is in **Italian**.): Il modello non riconosce correttamente le entità nominate.\n",
            "**Italian (original):**  \n",
            "Il modello non riconosce correttamente le entità nominate.\n",
            "\n",
            "**English translation:**  \n",
            "The model does not correctly recognize named entities.\n",
            "\n",
            "**Korean translation:**  \n",
            "모델이 명명된 엔터티를 정확히 인식하지 못합니다. \n",
            "\n",
            "Original message (That sentence is in **Polish**.): Mój system AI zużywa zbyt dużo pamięci RAM.\n",
            "**English:**  \n",
            "My AI system uses too much RAM.\n",
            "\n",
            "**Korean:**  \n",
            "내 AI 시스템이 너무 많은 RAM을 사용합니다. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIUo-c2n6yDc",
        "outputId": "dff70fca-c1d7-48c0-f30c-07f52c2a28cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Subject:** Standing Lamp Specification – Joe\n",
            "\n",
            "Dear [Recipient’s Name],\n",
            "\n",
            "I hope this message finds you well.\n",
            "\n",
            "I am writing to share the specifications for the standing lamp we discussed. Please find the detailed specification sheet attached for your review.\n",
            "\n",
            "Should you have any questions or require further clarification, feel free to contact me at your convenience.\n",
            "\n",
            "Thank you for your time and consideration.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "Joe  \n",
            "[Job Title]  \n",
            "[Company Name]  \n",
            "[Phone] | [Email] | [Website]\n"
          ]
        }
      ],
      "source": [
        "# Tone Transformation\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter:\n",
        "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4iuzEw18Xc3",
        "outputId": "d1229cb1-658d-4415-8caf-944fa1b6bac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here’s a ready‑to‑paste HTML snippet that turns the JSON data into a nicely formatted table with a title and column headers:\n",
            "\n",
            "```html\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "<meta charset=\"UTF-8\">\n",
            "<title>Restaurant Employees</title>\n",
            "<style>\n",
            "  table { border-collapse: collapse; width: 100%; }\n",
            "  th, td { border: 1px solid #333; padding: 8px; text-align: left; }\n",
            "  th { background: #f2f2f2; }\n",
            "</style>\n",
            "</head>\n",
            "<body>\n",
            "\n",
            "<h1>Restaurant Employees</h1>\n",
            "\n",
            "<table>\n",
            "  <caption>Restaurant Employees</caption>\n",
            "  <thead>\n",
            "    <tr>\n",
            "      <th>Name</th>\n",
            "      <th>Email</th>\n",
            "    </tr>\n",
            "  </thead>\n",
            "  <tbody>\n",
            "    <tr>\n",
            "      <td>Shyam</td>\n",
            "      <td>shyamjaiswal@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Bob</td>\n",
            "      <td>bob32@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Jai</td>\n",
            "      <td>jai87@gmail.com</td>\n",
            "    </tr>\n",
            "  </tbody>\n",
            "</table>\n",
            "\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "**What this does**\n",
            "\n",
            "- The `<h1>` tag gives the page a clear title.\n",
            "- The `<caption>` inside the table provides an accessible table title.\n",
            "- Column headers (`<th>`) are “Name” and “Email”.\n",
            "- Each employee record is rendered as a row in the `<tbody>`.\n"
          ]
        }
      ],
      "source": [
        "# Format Conversion\n",
        "\n",
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgrMOc_78iJC",
        "outputId": "c65cc4a4-7c03-44ae-b922-dca3135335da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The girl with the black and white puppies has a ball.\n",
            "No errors found\n",
            "It's going to be a long day. Does the car need its oil changed?\n",
            "Their goes my freedom. There going to bring them’s suitcases.\n",
            "You're going to need your notebook.\n",
            "That medicine affects my ability to sleep. Have you heard of the butterfly effect?\n",
            "This phrase is to check ChatGPT for spelling ability\n"
          ]
        }
      ],
      "source": [
        "# Spellcheck/Grammar check\n",
        "\n",
        "text = [\n",
        "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
        "  \"Yolanda has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
        "]\n",
        "for t in text:\n",
        "    prompt = f\"\"\"Proofread and correct the following text\n",
        "    and rewrite the corrected version. If you don't find\n",
        "    and errors, just say \"No errors found\". Don't use\n",
        "    any punctuation around the text:\n",
        "    ```{t}```\"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIIP5mVP8lrS",
        "outputId": "736fbd6f-e40f-45f9-a90f-0e5dd7aeafb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bought this smart speaker for my home office because I needed something to help manage reminders and play music while I work. The sound quality is pretty good for its size, and the voice assistant usually understands me well. However, sometimes it activates randomly when I’m not talking to it, which is annoying. The setup was simple and quick, and it connected to my Wi‑Fi without issues. Overall, it’s a nice addition, but I wish the microphone sensitivity could be adjusted more easily.\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "Bought this smart speaker for my home office because I needed \\\n",
        "something to help manage reminders and play music while I work. \\\n",
        "The sound quality is pretty good for its size, and the voice \\\n",
        "assistant usually understands me well. However, sometimes it \\\n",
        "activates randomly when I’m not talking to it, which is annoying. \\\n",
        "The setup was simple and quick, and it connected to my Wi-Fi \\\n",
        "without issues. Overall, it’s a nice addition, but I wish the \\\n",
        "microphone sensitivity could be adjusted more easily.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030546c6",
        "outputId": "748821cf-7435-4759-cbb8-063a12b63221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting redlines\n",
            "  Downloading redlines-0.5.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from redlines) (8.2.1)\n",
            "Collecting rich-click>=1.6.1 (from redlines)\n",
            "  Downloading rich_click-1.8.9-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: rich>=13.3.5 in /usr/local/lib/python3.12/dist-packages (from redlines) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.5->redlines) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.5->redlines) (2.19.2)\n",
            "Requirement already satisfied: typing_extensions>=4 in /usr/local/lib/python3.12/dist-packages (from rich-click>=1.6.1->redlines) (4.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.5->redlines) (0.1.2)\n",
            "Downloading redlines-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading rich_click-1.8.9-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: rich-click, redlines\n",
            "Successfully installed redlines-0.5.2 rich-click-1.8.9\n"
          ]
        }
      ],
      "source": [
        "!pip install redlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "HkWmUq-A83Kr",
        "outputId": "8a0cdf77-5090-4985-8ce0-9718d1cc400d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Bought this smart speaker for my home office because I needed something to help manage reminders and play music while I work. The sound quality is pretty good for its size, and the voice assistant usually understands me well. However, sometimes it activates randomly when I’m not talking to it, which is annoying. The setup was simple and quick, and it connected to my <span style='color:red;font-weight:700;text-decoration:line-through;'>Wi-Fi </span><span style='color:green;font-weight:700;'>Wi‑Fi </span>without issues. Overall, it’s a nice addition, but I wish the microphone sensitivity could be adjusted more easily."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from redlines import Redlines\n",
        "from IPython.display import Markdown\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D5VoauLS9JT5",
        "outputId": "4b113b9f-1b1e-46a9-b371-d211a51c8291"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Abstract  \n",
              "\n",
              "This review evaluates a compact AI‑enabled smart speaker acquired for a professional home‑office setting. The assessment focuses on acoustic performance, voice‑assistant reliability, network integration, and user‑interface ergonomics. While the device delivers commendable audio fidelity and seamless task‑management capabilities, occasional unintended wake‑word activation and limited microphone‑gain customization detract from an otherwise polished experience. The following sections provide a detailed, APA‑style analysis tailored to an advanced readership.\n",
              "\n",
              "## Product Overview  \n",
              "\n",
              "- **Form factor**: 5‑inch cylindrical enclosure with a matte black finish.  \n",
              "- **Audio architecture**: Dual 2.5‑inch tweeters and a 4‑inch woofer, delivering a 20–20 kHz frequency response.  \n",
              "- **Voice‑assistant platform**: Proprietary AI assistant with integrated calendar, email, and task‑management APIs.  \n",
              "- **Connectivity**: Dual‑band 802.11ac Wi‑Fi, Bluetooth 5.0, and a 3.5 mm audio output.  \n",
              "- **Power**: 5 V/2 A USB‑C supply.\n",
              "\n",
              "## Performance Evaluation  \n",
              "\n",
              "| Criterion | Observation | Implication |\n",
              "|-----------|-------------|-------------|\n",
              "| **Acoustic fidelity** | The speaker produces clear mids and a well‑balanced bass response for its size. | Suitable for background music and voice‑over clarity during video calls. |\n",
              "| **Voice‑assistant accuracy** | Recognition accuracy exceeds 90 % for standard commands; occasional misinterpretation of homophones. | Adequate for routine reminders but may require re‑training for specialized vocabularies. |\n",
              "| **Wake‑word detection** | Random activation occurs approximately 3–4 % of the time during periods of ambient noise. | Interrupts workflow; suggests suboptimal noise‑gating algorithms. |\n",
              "| **Microphone sensitivity** | Gain control is accessible only via the companion app, lacking on‑device sliders. | Limits real‑time fine‑tuning in dynamic acoustic environments. |\n",
              "| **Network integration** | Wi‑Fi pairing completes in under 30 s; no latency observed during streaming. | Reliable connectivity for continuous task synchronization. |\n",
              "\n",
              "## User Experience  \n",
              "\n",
              "- **Setup**: The initial configuration is intuitive; the companion app guides the user through Wi‑Fi onboarding and voice‑assistant calibration.  \n",
              "- **Reminders & task management**: Integration with Google Calendar and Todoist streamlines scheduling; voice‑activated reminders are delivered with minimal lag.  \n",
              "- **Music playback**: Supports Spotify, Apple Music, and local MP3 files via Bluetooth; audio quality remains consistent across platforms.  \n",
              "- **Random activation**: Occasional unsolicited responses interrupt concentration, particularly during meetings or focused work sessions.  \n",
              "- **Microphone‑gain customization**: The absence of an on‑device gain knob necessitates app‑based adjustments, which can be cumbersome in a fast‑paced work environment.\n",
              "\n",
              "### Pros  \n",
              "- Compact design with robust acoustic output.  \n",
              "- Seamless integration with major productivity suites.  \n",
              "- Rapid Wi‑Fi onboarding and stable streaming performance.  \n",
              "\n",
              "### Cons  \n",
              "- Unintended wake‑word activation disrupts workflow.  \n",
              "- Limited on‑device microphone‑gain control hampers adaptability to varying ambient noise levels.  \n",
              "\n",
              "## Conclusion  \n",
              "\n",
              "The smart speaker delivers a compelling blend of audio quality and productivity features that enhance a professional home‑office environment. Its strengths lie in reliable network connectivity, comprehensive task‑management integration, and a pleasing acoustic profile for its dimensions. However, the device’s propensity for accidental wake‑word activation and the lack of granular microphone‑gain controls represent notable shortcomings for users operating in acoustically variable settings. Future iterations would benefit from refined noise‑gating algorithms and an on‑device gain adjustment interface to fully satisfy the demands of advanced, multitasking professionals."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
