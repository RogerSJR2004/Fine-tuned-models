{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMsGgNjdQKfC",
        "outputId": "6c550b9f-92d4-4925-b878-4dfc3ab33785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4rugF9pSOMR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=\"--\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "86TrTWfVSQy3"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"openai/gpt-oss-20b\"):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WPiwKh7WSUTT"
      },
      "outputs": [],
      "source": [
        "review = \"\"\"\n",
        "Wanted a smartwatch mainly for fitness tracking, and this \\\n",
        "one looked like a good balance of features and price. \\\n",
        "Shipping was quick — arrived in just two days and the box \\\n",
        "was neatly packed. Setup was super easy, just a few taps \\\n",
        "to pair it with my phone. The heart rate and step tracking \\\n",
        "seem accurate, and I really like the reminders to stand up \\\n",
        "and move around when I’ve been sitting too long. The first \\\n",
        "strap I received had a loose clasp, so I reached out to \\\n",
        "support and they immediately sent me a replacement, which \\\n",
        "arrived within a few days. The screen is bright and easy \\\n",
        "to read outdoors, and the battery lasts me about five days \\\n",
        "on a single charge. I do wish it had more customization \\\n",
        "for workouts, but overall I’m really happy with it. FitX \\\n",
        "seems like a solid company that actually listens to its \\\n",
        "customers!\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyjQIv1RSiI4",
        "outputId": "6fdb76e5-4fdd-4e68-9f6f-5881112b284c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Sentiment:** Positive.\n"
          ]
        }
      ],
      "source": [
        "#Sentiment (positive/negative)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtfHVGwASk3f",
        "outputId": "03b814cb-0a40-4c92-d87b-ea44d7f8bde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is delimited with triple backticks?\n",
        "\n",
        "Give your answer as a single word, either \"positive\" \\\n",
        "or \"negative\".\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t6jCgrtSv1h",
        "outputId": "fa26a7cd-9a90-4f50-8c9d-d58af1589d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy, satisfied, relieved, grateful, appreciative\n"
          ]
        }
      ],
      "source": [
        "# Identify types of emotions\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJFJUVXVS3H1",
        "outputId": "bc00a413-8069-42fd-edcb-4ccbb6fd6959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no\n"
          ]
        }
      ],
      "source": [
        "# Identify anger\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ_io_SfTHk-"
      },
      "source": [
        "# Extract product and company name from customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmXeMHsrTC6Q",
        "outputId": "41055b81-c9cb-4d82-b2b9-0b42ae4fe4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Item\":\"smartwatch\",\"Brand\":\"FitX\"}\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_aHKAgyTKZ_",
        "outputId": "672439ee-2e9c-471d-b959-acff005e7843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Sentiment\":\"positive\",\"Anger\":false,\"Item\":\"smartwatch\",\"Brand\":\"FitX\"}\n"
          ]
        }
      ],
      "source": [
        "# Doing multiple tasks at once\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GcHFhUWT80P"
      },
      "source": [
        "# Inferring topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H3p5VMyUTuHT"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government,\n",
        "public sector employees were asked to rate their level\n",
        "of satisfaction with the department they work at.\n",
        "The results revealed that GraceUP was the most popular\n",
        "organization with a satisfaction rating of 95%.\n",
        "\n",
        "One GraceUP employee, John Smith, commented on the findings,\n",
        "stating, \"I’m not surprised that GraceUP came out on top.\n",
        "It’s a fantastic place to work with supportive colleagues\n",
        "and inspiring projects. I’m proud to be a part of such a\n",
        "forward-thinking organization.\"\n",
        "\n",
        "The results were also welcomed by GraceUP’s management team,\n",
        "with Director Tom Johnson stating, \"We are delighted to see\n",
        "such positive feedback from our employees. At GraceUP, we\n",
        "strive to create an environment where our people feel valued\n",
        "and motivated, and it’s rewarding to know that effort is\n",
        "making a difference.\"\n",
        "\n",
        "The survey also revealed that the\n",
        "Social Security Administration had the lowest satisfaction\n",
        "rating, with only 45% of employees indicating they were\n",
        "satisfied with their job. The government has pledged to\n",
        "address the concerns raised by employees in the survey and\n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zILv197BUOC1",
        "outputId": "a9a05ba4-03a5-4e3c-ef69-475738d057a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraceUP, employee satisfaction, survey, government, Social Security Administration\n"
          ]
        }
      ],
      "source": [
        "#Infer 5 topics\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long.\n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M46tM-OUQ2e",
        "outputId": "9b952923-ca76-414d-dcbb-b8dbd19ad230"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['GraceUP',\n",
              " ' employee satisfaction',\n",
              " ' survey',\n",
              " ' government',\n",
              " ' Social Security Administration']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.split(sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3cKVojsCUX6R"
      },
      "outputs": [],
      "source": [
        "topic_list = [\n",
        "    \"GraceUP\", \"public sector\", \"employee satisfaction\",\n",
        "    \"government survey\", \"workplace culture\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvFc2ySzUmc2",
        "outputId": "ce28ebc7-8d1a-456f-ff7b-bfd9ea6d2e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraceUP: 1  \n",
            "public sector: 1  \n",
            "employee satisfaction: 1  \n",
            "government survey: 1  \n",
            "workplace culture: 1\n"
          ]
        }
      ],
      "source": [
        "# Make a news alert for certain topics\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as follows:\n",
        "item from the list: 0 or 1\n",
        "\n",
        "List of topics: {\", \".join(topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb3Fy3woUsDD",
        "outputId": "c2446cdc-2f21-4e15-850d-8cee3977f67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALERT: New GraceUP story!\n"
          ]
        }
      ],
      "source": [
        "topic_dict = {i.split(': ')[0]: int(i.split(': ')[1]) for i in response.split(sep='\\n')}\n",
        "if topic_dict['GraceUP'] == 1:\n",
        "    print(\"ALERT: New GraceUP story!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-1CElwjVNIk"
      },
      "source": [
        "# Theory about Inferring\n",
        "\n",
        "In **prompt engineering**, *inferring* usually refers to how an AI model **draws conclusions or extracts meaning** from the input you provide — even if that meaning isn’t stated explicitly.\n",
        "\n",
        "Here’s the breakdown:\n",
        "\n",
        "### 🔹 What “inferring” means in this context\n",
        "\n",
        "* It’s the model’s ability to **connect dots** and **derive hidden intent** behind a prompt.\n",
        "* Instead of just repeating instructions, the AI interprets **implied goals, context, or constraints**.\n",
        "* Basically: *“What is the user really asking me to do here?”*\n",
        "\n",
        "### 🔹 Example\n",
        "\n",
        "Prompt:\n",
        "\n",
        "> “Write a short email apologizing for a delivery delay.”\n",
        "\n",
        "The AI **infers** that:\n",
        "\n",
        "* The email should be professional and polite.\n",
        "* The writer is likely representing a company.\n",
        "* The tone should acknowledge the delay and offer reassurance.\n",
        "\n",
        "Even though none of that is explicitly spelled out, the model pulls it from context.\n",
        "\n",
        "### 🔹 Why it matters in prompt engineering\n",
        "\n",
        "When you design prompts, you can either:\n",
        "\n",
        "1. **Rely on inference** (let the AI fill in gaps using common sense/context), or\n",
        "2. **Minimize inference** (spell things out clearly so the AI doesn’t make assumptions).\n",
        "\n",
        "Balancing this is key: too much inference can cause *hallucinations* or wrong assumptions, but too little can make prompts clunky and over-engineered.\n",
        "\n",
        "---\n",
        "\n",
        "⚡ In short: **Inferring in prompt engineering is the model’s way of reading between the lines to understand intent, context, or missing details.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5w6OBd5Uz0H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
